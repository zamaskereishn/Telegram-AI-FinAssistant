"""
–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞
"""

from typing import List, Dict
import re
from datetime import datetime, timedelta
from database import get_db, Digest, User
from loguru import logger


def clean_html(text: str) -> str:
    """–û—á–∏—Å—Ç–∫–∞ HTML —Ç–µ–≥–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)


def truncate_text(text: str, max_length: int = 300) -> str:
    """–û–±—Ä–µ–∑–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Å–ª–æ–≤"""
    if len(text) <= max_length:
        return text

    truncated = text[:max_length].rsplit(' ', 1)[0]
    return truncated + '...'


def format_currency(value: str) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞–ª—é—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
    try:
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
        clean_value = re.sub(r'[^\d.,]', '', value)
        clean_value = clean_value.replace(',', '.')

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Å–ª–æ
        num = float(clean_value)
        return f"{num:.2f}"
    except (ValueError, AttributeError):
        return value


def validate_url(url: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ URL"""
    url_pattern = re.compile(
        r'^https?://'  # http:// or https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domain...
        r'localhost|'  # localhost...
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # ...or ip
        r'(?::\d+)?'  # optional port
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)

    return url_pattern.match(url) is not None


def get_digest_stats(days: int = 7) -> Dict:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞–º"""
    db = get_db()
    try:
        start_date = datetime.now() - timedelta(days=days)

        digests = db.query(Digest).filter(
            Digest.created_at >= start_date
        ).all()

        return {
            'total_digests': len(digests),
            'published': len([d for d in digests if d.status == 'published']),
            'failed': len([d for d in digests if d.status == 'failed']),
            'drafts': len([d for d in digests if d.status == 'draft']),
        }
    finally:
        db.close()


def get_user_stats() -> Dict:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º"""
    db = get_db()
    try:
        users = db.query(User).all()

        return {
            'total_users': len(users),
            'active_users': len([u for u in users if u.is_active]),
            'inactive_users': len([u for u in users if not u.is_active]),
        }
    finally:
        db.close()


def format_digest_for_telegram(digest: str) -> List[str]:
    """
    –†–∞–∑–±–∏–≤–∫–∞ –¥–ª–∏–Ω–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è Telegram
    (–º–∞–∫—Å–∏–º—É–º 4096 —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏)
    """
    max_length = 4000  # –û—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å

    if len(digest) <= max_length:
        return [digest]

    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º (–æ–Ω–∏ –æ–±—ã—á–Ω–æ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å —ç–º–æ–¥–∑–∏)
    sections = re.split(r'(\n\n[üìäüí±üè¶üìà‚ö†Ô∏è])', digest)

    messages = []
    current_message = ""

    for section in sections:
        if len(current_message) + len(section) <= max_length:
            current_message += section
        else:
            if current_message:
                messages.append(current_message.strip())
            current_message = section

    if current_message:
        messages.append(current_message.strip())

    return messages


def escape_markdown(text: str) -> str:
    """–≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è Markdown"""
    special_chars = ['_', '*', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']

    for char in special_chars:
        text = text.replace(char, f'\\{char}')

    return text


def get_latest_digest() -> Dict:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞"""
    db = get_db()
    try:
        digest = db.query(Digest).filter(
            Digest.status == 'published'
        ).order_by(Digest.date.desc()).first()

        if digest:
            return {
                'id': digest.id,
                'date': digest.date,
                'summary': digest.summary,
                'categories': digest.categories,
            }
        return None
    finally:
        db.close()


def extract_keywords(text: str, top_n: int = 10) -> List[str]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤
    # –ú–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å –ø–æ–º–æ—â—å—é NLP –±–∏–±–ª–∏–æ—Ç–µ–∫

    # –£–±–∏—Ä–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ lowercase
    words = re.findall(r'\b\w+\b', text.lower())

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ (–±–∞–∑–æ–≤—ã–π —Å–ø–∏—Å–æ–∫)
    stop_words = {
        '–∏', '–≤', '–Ω–∞', '—Å', '–ø–æ', '–¥–ª—è', '–Ω–µ', '—á—Ç–æ', '—ç—Ç–æ', '–∫–∞–∫',
        '–∏–∑', '–æ', '–∫', '–¥–æ', '–æ—Ç', '—É', '–∑–∞', '–ø—Ä–∏', '—Ç–∞–∫', '–Ω–æ',
        '–∞', '–∏–ª–∏', '–∂–µ', '–±—ã', '–ª–∏', '–∂–µ', '—É–∂–µ', '–¥–∞–∂–µ', '–Ω–∏'
    }

    filtered_words = [w for w in words if len(w) > 3 and w not in stop_words]

    # –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç—ã
    word_freq = {}
    for word in filtered_words:
        word_freq[word] = word_freq.get(word, 0) + 1

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —á–∞—Å—Ç–æ—Ç–µ
    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)

    return [word for word, freq in sorted_words[:top_n]]


def backup_database(backup_dir: str = 'backups'):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –ë–î"""
    import os
    import subprocess
    from pathlib import Path

    backup_path = Path(backup_dir)
    backup_path.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_file = backup_path / f'finbot_backup_{timestamp}.sql'

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º pg_dump –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞
        # –¢—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ .pgpass –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        subprocess.run([
            'pg_dump',
            '-h', 'localhost',
            '-U', 'finbot_user',
            '-d', 'finbot_db',
            '-f', str(backup_file)
        ], check=True)

        logger.info(f"Backup created: {backup_file}")
        return str(backup_file)
    except subprocess.CalledProcessError as e:
        logger.error(f"Backup failed: {e}")
        return None


def health_check() -> Dict:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
    health = {
        'database': False,
        'telegram_api': False,
        'gemini_api': False,
        'scraper': False,
    }

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ë–î
    try:
        db = get_db()
        db.query(User).first()
        db.close()
        health['database'] = True
    except Exception as e:
        logger.error(f"DB health check failed: {e}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Telegram API
    try:
        from config import config
        if config.TELEGRAM_BOT_TOKEN:
            health['telegram_api'] = True
    except Exception as e:
        logger.error(f"Telegram health check failed: {e}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Gemini API
    try:
        from config import config
        if config.GEMINI_API_KEY:
            health['gemini_api'] = True
    except Exception as e:
        logger.error(f"Gemini health check failed: {e}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞
    try:
        from scraper import FinancialScraper
        scraper = FinancialScraper()
        health['scraper'] = True
    except Exception as e:
        logger.error(f"Scraper health check failed: {e}")

    return health


def generate_report(days: int = 7) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ —Ä–∞–±–æ—Ç–µ –±–æ—Ç–∞"""
    digest_stats = get_digest_stats(days)
    user_stats = get_user_stats()
    health = health_check()

    report = f"""
üìä **–û—Ç—á–µ—Ç –æ —Ä–∞–±–æ—Ç–µ –±–æ—Ç–∞**

–ü–µ—Ä–∏–æ–¥: –ø–æ—Å–ª–µ–¥–Ω–∏–µ {days} –¥–Ω–µ–π

**–î–∞–π–¥–∂–µ—Å—Ç—ã:**
‚Ä¢ –í—Å–µ–≥–æ: {digest_stats['total_digests']}
‚Ä¢ –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: {digest_stats['published']}
‚Ä¢ –ß–µ—Ä–Ω–æ–≤–∏–∫–∏: {digest_stats['drafts']}
‚Ä¢ –û—à–∏–±–∫–∏: {digest_stats['failed']}

**–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏:**
‚Ä¢ –í—Å–µ–≥–æ: {user_stats['total_users']}
‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö: {user_stats['active_users']}
‚Ä¢ –ù–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö: {user_stats['inactive_users']}

**–°—Ç–∞—Ç—É—Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:**
‚Ä¢ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {'‚úì' if health['database'] else '‚úó'}
‚Ä¢ Telegram API: {'‚úì' if health['telegram_api'] else '‚úó'}
‚Ä¢ Gemini API: {'‚úì' if health['gemini_api'] else '‚úó'}
‚Ä¢ –ü–∞—Ä—Å–µ—Ä: {'‚úì' if health['scraper'] else '‚úó'}

–î–∞—Ç–∞ –æ—Ç—á–µ—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

    return report


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    print(generate_report())